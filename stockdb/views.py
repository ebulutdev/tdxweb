import logging
import json
from datetime import datetime, timedelta, timezone
import base64
import requests
import urllib.parse
import re
import time
import hashlib
from django.http import HttpResponse, JsonResponse
from django.views.decorators.csrf import csrf_exempt, csrf_protect
from django.shortcuts import render, redirect, get_object_or_404
from django.core.cache import cache
from django.urls import reverse
from bs4 import BeautifulSoup
import feedparser
from dateutil import parser as dateparser
from .models import Stock, RecommendedStock, QuestionAnswer, StockImage
from .utils import get_stock_data
from yfinance.data import YFRateLimitError
from curl_cffi import requests as curl_requests
from django.views.decorators.cache import cache_page
from django.views.decorators.http import require_GET
from django.contrib.auth import authenticate, login, logout
from django.contrib.auth.models import User
from django.contrib import messages
from django.core.mail import send_mail
import random
import yfinance as yf
import google.generativeai as genai

# PIL import'unu koÅŸullu hale getir
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("PIL (Pillow) modÃ¼lÃ¼ bulunamadÄ±. GÃ¶rsel analizi Ã¶zelliÄŸi devre dÄ±ÅŸÄ±.")

from django.contrib.auth.decorators import login_required, permission_required

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Cache settings
CACHE_DIR = "cache"
CACHE_TIMEOUTS = {
    'stock_data': 5 * 60,  # 5 minutes
    'analysis': 60 * 60,   # 1 hour
    'news': 30 * 60,      # 30 minutes
    'chat_history': 30 * 60,  # 30 minutes
}

# Samimi karÅŸÄ±lama mesajlarÄ±
GREETING_MESSAGES = [
    "Merhaba! Ben TDX AI Bot. Borsa konusunda size yardÄ±mcÄ± olmak iÃ§in buradayÄ±m! ğŸ“ˆ",
    "Selam! TDX AI Bot olarak hizmetinizdeyim. Birlikte piyasalarÄ± analiz edelim! ğŸ’¹",
    "HoÅŸ geldiniz! Ben TDX AI Bot, finansal piyasalardaki asistanÄ±nÄ±z. Size nasÄ±l yardÄ±mcÄ± olabilirim? ğŸ¤",
    "Merhaba! Borsada yolunuzu bulmak iÃ§in buradayÄ±m. Hangi konuda yardÄ±ma ihtiyacÄ±nÄ±z var? ğŸ¯"
]

# Hisse analizi iÃ§in prompt template
STOCK_ANALYSIS_TEMPLATE = """
Merhaba! Ben TDX AI Bot. {symbol} hissesi iÃ§in detaylÄ± bir analiz hazÄ±rladÄ±m:

Teknik Veriler:
{technical_data}

Son 1 AylÄ±k Performans:
{performance_summary}

Ã–nemli GÃ¶stergeler:
{key_indicators}

Benim Yorumum:
{analysis}

Size nasÄ±l yardÄ±mcÄ± olabilirim? BaÅŸka bir hisse iÃ§in analiz yapmamÄ± ister misiniz? ğŸ“Š
"""

class RateLimiter:
    def __init__(self, key_prefix, limit, period):
        self.key_prefix = key_prefix
        self.limit = limit
        self.period = period

    def is_allowed(self, identifier):
        cache_key = f"{self.key_prefix}_{identifier}"
        current = cache.get(cache_key)
        if current is None:
            cache.set(cache_key, 1, self.period)
            return True
        if current >= self.limit:
            return False
        cache.incr(cache_key)
        return True

STOCK_LIMITER = RateLimiter('stock', 60, 60)  # 60 requests/minute

class TDXBotRateLimiter:
    def __init__(self, max_requests=60, time_window=60):
        self.max_requests = max_requests
        self.time_window = time_window
        self.cache_prefix = "tdx_bot_ratelimit"

    def is_allowed(self, user_id):
        cache_key = f"{self.cache_prefix}_{user_id}"
        current_usage = cache.get(cache_key, 0)
        
        if current_usage >= self.max_requests:
            return False
        
        cache.set(cache_key, current_usage + 1, self.time_window)
        return True

rate_limiter = TDXBotRateLimiter()

def get_latest_news(symbol="MIATK", count=10):
    symbol = symbol.upper()
    query = f"{symbol} hisse"
    query_encoded = urllib.parse.quote(query)
    url = f"https://news.google.com/rss/search?q={query_encoded}&hl=tr&gl=TR&ceid=TR:tr"
    feed = feedparser.parse(url)
    news_data = []
    for entry in feed.entries:
        # Sadece baÅŸlÄ±k veya Ã¶zetinde MIATK geÃ§enleri al
        title = entry.title if 'title' in entry else ""
        summary = entry.summary if 'summary' in entry else ""
        if symbol in title.upper() or symbol in summary.upper():
            # Kaynak bilgisini bul
            source = ''
            if 'source' in entry and entry.source and hasattr(entry.source, 'title'):
                source = entry.source.title
            elif 'summary' in entry and entry.summary:
                match = re.search(r'-\s*([\wÃ‡Ã§ÄÄŸÄ°Ä±Ã–Ã¶ÅÅŸÃœÃ¼\s]+)$', entry.summary)
                if match:
                    source = match.group(1).strip()
            elif 'title' in entry and entry.title:
                match = re.search(r'-\s*([\wÃ‡Ã§ÄÄŸÄ°Ä±Ã–Ã¶ÅÅŸÃœÃ¼\s]+)$', entry.title)
                if match:
                    source = match.group(1).strip()
            news_data.append({
                'title': title,
                'link': entry.link,
                'summary': summary,
                'published': entry.published if 'published' in entry else "",
                'source': source
            })
        if len(news_data) >= count:
            break
    return news_data

def find_support_resistance(prices):
    support_levels = []
    resistance_levels = []
    for i in range(1, len(prices)-1):
        if prices[i] < prices[i-1] and prices[i] < prices[i+1]:
            support_levels.append(prices[i])
        elif prices[i] > prices[i-1] and prices[i] > prices[i+1]:
            resistance_levels.append(prices[i])
    return support_levels, resistance_levels

def scrape_bist_news(symbol=None, company_name=None, count=10, days=30):
    import feedparser
    import urllib.parse
    import re
    from dateutil import parser as dateparser
    from datetime import datetime, timedelta, timezone

    queries = []
    if symbol:
        queries.append(f"{symbol} BIST")
        queries.append(f"{symbol}")
    if company_name:
        queries.append(f"{company_name} BIST")
        queries.append(f"{company_name}")
    queries.append("BIST Borsa Ä°stanbul")

    news_data = []
    seen_links = set()
    now = datetime.now(timezone.utc)
    min_date = now - timedelta(days=days)
    symbol_key = symbol.lower().replace('.is', '') if symbol else None
    company_key = company_name.lower() if company_name else None

    for query in queries:
        query_encoded = urllib.parse.quote(query)
        url = f"https://news.google.com/rss/search?q={query_encoded}&hl=tr&gl=TR&ceid=TR:tr"
        feed = feedparser.parse(url)
        for entry in feed.entries:
            if entry.link in seen_links:
                continue  # AynÄ± haberi tekrar ekleme
            seen_links.add(entry.link)
            title_lower = entry.title.lower()
            summary_lower = (entry.summary if 'summary' in entry else '').lower()
            # Filtre: baÅŸlÄ±k veya Ã¶zet iÃ§inde sembol veya ÅŸirket adÄ± geÃ§meli
            if symbol_key and symbol_key not in title_lower and (not company_key or company_key not in title_lower) and symbol_key not in summary_lower and (not company_key or company_key not in summary_lower):
                continue
            source = ''
            if 'source' in entry and entry.source and hasattr(entry.source, 'title'):
                source = entry.source.title
            elif 'summary' in entry and entry.summary:
                match = re.search(r'-\s*([\wÃ‡Ã§ÄÄŸÄ°Ä±Ã–Ã¶ÅÅŸÃœÃ¼\s]+)$', entry.summary)
                if match:
                    source = match.group(1).strip()
            elif 'title' in entry and entry.title:
                match = re.search(r'-\s*([\wÃ‡Ã§ÄÄŸÄ°Ä±Ã–Ã¶ÅÅŸÃœÃ¼\s]+)$', entry.title)
                if match:
                    source = match.group(1).strip()
            published = entry.published if 'published' in entry else ""
            try:
                published_dt = dateparser.parse(published)
                if published_dt is not None and published_dt.tzinfo is None:
                    published_dt = published_dt.replace(tzinfo=timezone.utc)
            except Exception:
                published_dt = None
            # Sadece son X gÃ¼n iÃ§indeki haberleri al
            if published_dt is None or published_dt < min_date or published_dt > now + timedelta(days=1):
                continue
            news_data.append({
                'title': entry.title,
                'link': entry.link,
                'summary': entry.summary if 'summary' in entry else "",
                'published': published,
                'published_dt': published_dt,
                'source': source
            })
            if len(news_data) >= count:
                break
        if len(news_data) >= count:
            break

    # EÄŸer hiÃ§ haber yoksa, genel BIST haberlerinden doldur
    if not news_data:
        query_encoded = urllib.parse.quote("BIST Borsa Ä°stanbul")
        url = f"https://news.google.com/rss/search?q={query_encoded}&hl=tr&gl=TR&ceid=TR:tr"
        feed = feedparser.parse(url)
        for entry in feed.entries:
            if entry.link in seen_links:
                continue
            seen_links.add(entry.link)
            published = entry.published if 'published' in entry else ""
            try:
                published_dt = dateparser.parse(published)
                if published_dt is not None and published_dt.tzinfo is None:
                    published_dt = published_dt.replace(tzinfo=timezone.utc)
            except Exception:
                published_dt = None
            if published_dt is None or published_dt < min_date or published_dt > now + timedelta(days=1):
                continue
            news_data.append({
                'title': entry.title,
                'link': entry.link,
                'summary': entry.summary if 'summary' in entry else "",
                'published': published,
                'published_dt': published_dt,
                'source': entry.source.title if 'source' in entry and entry.source and hasattr(entry.source, 'title') else ""
            })
            if len(news_data) >= count:
                break

    # En gÃ¼ncel 10 haberi sÄ±rala ve dÃ¶ndÃ¼r
    news_data.sort(key=lambda x: x['published_dt'], reverse=True)
    return news_data[:count]

def save_news_to_json(symbol, news, out_dir=CACHE_DIR):
    try:
        os.makedirs(out_dir, exist_ok=True)
        news_file = os.path.join(out_dir, f"{symbol}_news.json")
        with open(news_file, 'w', encoding='utf-8') as f:
            json.dump({
                "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "news": news
            }, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Error saving news for {symbol}: {e}")

def stock_plot(request):
    import plotly.graph_objs as go
    import plotly.io as pio
    import pandas as pd
    import yfinance as yf
    
    symbol = request.GET.get('symbol', 'MIATK.IS').upper()
    symbol_to_company = {
        'THYAO.IS': 'TÃ¼rk Hava YollarÄ±',
        'GARAN.IS': 'Garanti BankasÄ±',
        'AKBNK.IS': 'Akbank',
        'SISE.IS': 'ÅiÅŸecam',
        'YKBNK.IS': 'YapÄ± Kredi',
        'KCHOL.IS': 'KoÃ§ Holding',
        'EREGL.IS': 'EreÄŸli Demir Ã‡elik',
        'SASA.IS': 'Sasa Polyester',
        'TUPRS.IS': 'TÃ¼praÅŸ',
        'ISCTR.IS': 'Ä°ÅŸ BankasÄ±',
        'MIATK.IS': 'Mia Teknoloji',
    }
    company_name = symbol_to_company.get(symbol, None)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)
    cache_key = f"yf_{symbol}_{start_date.date()}_{end_date.date()}"
    hist = cache.get(cache_key)
    if hist is None:
        try:
            stock = yf.Ticker(symbol)
            hist_df = stock.history(start=start_date, end=end_date)
            hist = {
                'index': [str(d.date()) for d in hist_df.index],
                'close': [float(c) for c in hist_df['Close']]
            }
            cache.set(cache_key, hist, timeout=60*60)
        except YFRateLimitError:
            return render(request, 'stock_plot.html', {
                'plotly_html': '',
                'dates': '[]',
                'closes': '[]',
                'news': [],
                'symbol': symbol,
                'error': 'Ã‡ok fazla istek gÃ¶nderdiniz. LÃ¼tfen birkaÃ§ dakika sonra tekrar deneyin.'
            })
        except Exception as e:
            return render(request, 'stock_plot.html', {
                'plotly_html': '',
                'dates': '[]',
                'closes': '[]',
                'news': [],
                'symbol': symbol,
                'error': f'Hata: {str(e)}'
            })
    dates = hist['index']
    closes = hist['close']
    support_levels, resistance_levels = find_support_resistance(closes)
    # Profesyonel Ã§izgi grafik
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=dates,
        y=closes,
        mode='lines+markers',
        name='Fiyat',
        line=dict(color='#1976d2', width=4, shape='spline', smoothing=1.3),
        marker=dict(size=8, color='#1976d2', line=dict(width=2, color='white'), symbol='circle'),
        hovertemplate='<b>%{x}</b><br>Fiyat: %{y:.2f} TL<br><extra></extra>',
    ))
    # Son 1 haftadaki haberleri grafiÄŸe ekle
    news = scrape_bist_news(symbol, company_name, count=10, days=7)
    news_dates = []
    news_titles = []
    news_summaries = []
    for item in news:
        try:
            news_date = pd.to_datetime(item['published']).date()
            if str(news_date) in dates:
                news_dates.append(str(news_date))
                news_titles.append(item['title'])
                news_summaries.append(item['summary'])
        except Exception:
            continue
    if news_dates:
        fig.add_trace(go.Scatter(
            x=news_dates,
            y=[closes[dates.index(d)] for d in news_dates],
            mode='markers',
            name='Haber',
            marker=dict(size=10, color='#ffd600', symbol='star'),
            hovertemplate='<b>%{customdata[0]}</b><br><span style="font-size:12px;">%{customdata[2]}</span><extra>Haber</extra>',
            customdata=[(t, s, (s[:50] + '...') if len(s) > 50 else s) for t, s in zip(news_titles, news_summaries)]
        ))
    for s in support_levels:
        fig.add_hline(y=s, line=dict(color='rgba(0,200,83,0.7)', width=2, dash='dot'), name='Destek')
    for r in resistance_levels:
        fig.add_hline(y=r, line=dict(color='rgba(229,57,53,0.7)', width=2, dash='dot'), name='DirenÃ§')
    fig.update_layout(
        title=f'{symbol} Son 1 AylÄ±k KapanÄ±ÅŸ FiyatlarÄ±',
        xaxis_title='Tarih',
        yaxis_title='Fiyat (TL)',
        plot_bgcolor='#23272e',
        paper_bgcolor='#181a20',
        font=dict(color='#e0e0e0', size=17),
        xaxis=dict(gridcolor='#444857', showgrid=True),
        yaxis=dict(gridcolor='#444857', showgrid=True),
        height=600,
        width=1000,
        margin=dict(l=60, r=40, t=60, b=60),
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
            bgcolor='rgba(0,0,0,0.2)'
        )
    )
    plotly_html = pio.to_html(fig, full_html=False)
    news = scrape_bist_news(symbol, company_name)
    return render(request, 'stock_plot.html', {
        'plotly_html': plotly_html,
        'dates': json.dumps(dates),
        'closes': json.dumps(closes),
        'news': news,
        'symbol': symbol,
        'error': ''
    })

def get_important_news(days=2):
    """PiyasayÄ± etkileyecek Ã¶nemli haberleri kategorilere gÃ¶re Ã§eker (cache'li)"""
    cache_key = f"important_news_{days}"
    cached = cache.get(cache_key)
    if cached:
        return cached
    categories = {
        'Merkez BankasÄ±': [
            'tcmb faiz kararÄ±', 'politika faizi', 'faiz artÄ±ÅŸÄ±', 'faiz indirimi',
            'tcmb baÅŸkanÄ±', 'tcmb toplantÄ±sÄ±', 'faiz kararÄ±', 'faiz beklentisi',
            'swap', 'rezerv', 'dÃ¶viz mÃ¼dahalesi', 'piyasa likiditesi'
        ],
        'Ekonomik Veriler': [
            'enflasyon verisi', 'iÅŸsizlik verisi', 'bÃ¼yÃ¼me verisi', 'gsyh',
            'cari aÃ§Ä±k', 'dÄ±ÅŸ ticaret aÃ§Ä±ÄŸÄ±', 'bÃ¼tÃ§e aÃ§Ä±ÄŸÄ±', 'merkez bankasÄ± rezerv',
            'dÃ¶viz rezervi', 'altÄ±n rezervi', 'sanayi Ã¼retimi', 'perakende satÄ±ÅŸ',
            'konut satÄ±ÅŸlarÄ±', 'tÃ¼ketici gÃ¼ven endeksi', 'reel sektÃ¶r gÃ¼ven endeksi'
        ],
        'Kurumsal Haberler': [
            'hisse senedi', 'temettÃ¼', 'bedelsiz', 'bedelli', 'halka arz',
            'yatÄ±rÄ±m kararÄ±', 'yatÄ±rÄ±m planÄ±', 'fabrika yatÄ±rÄ±mÄ±', 'ihracat anlaÅŸmasÄ±',
            'stratejik ortaklÄ±k', 'birleÅŸme', 'satÄ±n alma', 'borÃ§lanma', 'kredi',
            'finansman', 'sermaye artÄ±rÄ±mÄ±', 'Ã¶zel durum aÃ§Ä±klamasÄ±'
        ],
        'SektÃ¶rel GeliÅŸmeler': [
            'enerji fiyatlarÄ±', 'petrol fiyatÄ±', 'doÄŸalgaz fiyatÄ±', 'elektrik fiyatÄ±',
            'Ã§elik fiyatÄ±', 'demir fiyatÄ±', 'bakÄ±r fiyatÄ±', 'altÄ±n fiyatÄ±',
            'tarÄ±m Ã¼rÃ¼nleri', 'gÄ±da fiyatlarÄ±', 'emlak fiyatlarÄ±', 'kiralar',
            'inÅŸaat maliyetleri', 'hammadde fiyatlarÄ±', 'lojistik maliyetleri'
        ],
        'Piyasa Analizleri': [
            'piyasa analizi', 'teknik analiz', 'yatÄ±rÄ±m tavsiyesi', 'portfÃ¶y yÃ¶netimi',
            'risk analizi', 'piyasa beklentisi', 'piyasa gÃ¶rÃ¼nÃ¼mÃ¼', 'sektÃ¶r raporu',
            'ekonomi raporu', 'piyasa deÄŸerlendirmesi', 'yatÄ±rÄ±mcÄ± gÃ¶rÃ¼ÅŸÃ¼',
            'analist gÃ¶rÃ¼ÅŸÃ¼', 'piyasa yorumu'
        ]
    }
    queries = [
        "BIST borsa istanbul Ã¶nemli geliÅŸme",
        "TCMB faiz kararÄ± politika faizi",
        "ekonomik veri aÃ§Ä±klamasÄ± enflasyon bÃ¼yÃ¼me",
        "hisse senedi temettÃ¼ bedelsiz halka arz",
        "piyasa analizi yatÄ±rÄ±m tavsiyesi",
        "enerji fiyatlarÄ± petrol doÄŸalgaz elektrik",
        "Ã§elik demir bakÄ±r altÄ±n fiyatlarÄ±",
        "dÃ¶viz kuru analizi piyasa yorumu",
        "Ã¶zel durum aÃ§Ä±klamasÄ± sermaye artÄ±rÄ±mÄ±",
        "yatÄ±rÄ±m kararÄ± fabrika yatÄ±rÄ±mÄ±"
    ]
    news_data = []
    seen_links = set()
    now = datetime.now(timezone.utc)
    min_date = now - timedelta(days=days)
    for query in queries:
        query_encoded = urllib.parse.quote(query)
        url = f"https://news.google.com/rss/search?q={query_encoded}&hl=tr&gl=TR&ceid=TR:tr"
        feed = feedparser.parse(url)
        for entry in feed.entries:
            if entry.link in seen_links:
                continue
            seen_links.add(entry.link)
            title_lower = entry.title.lower()
            summary_lower = (entry.summary if 'summary' in entry else '').lower()
            category = 'DiÄŸer'
            for cat, keywords in categories.items():
                if any(keyword in title_lower or keyword in summary_lower for keyword in keywords):
                    category = cat
                    break
            if category == 'DiÄŸer':
                continue
            source = ''
            if 'source' in entry and entry.source and hasattr(entry.source, 'title'):
                source = entry.source.title
            elif 'summary' in entry and entry.summary:
                match = re.search(r'-\s*([\wÃ‡Ã§ÄÄŸÄ°Ä±Ã–Ã¶ÅÅŸÃœÃ¼\s]+)$', entry.summary)
                if match:
                    source = match.group(1).strip()
            elif 'title' in entry and entry.title:
                match = re.search(r'-\s*([\wÃ‡Ã§ÄÄŸÄ°Ä±Ã–Ã¶ÅÅŸÃœÃ¼\s]+)$', entry.title)
                if match:
                    source = match.group(1).strip()
            published = entry.published if 'published' in entry else ""
            try:
                published_dt = dateparser.parse(published)
                if published_dt is not None and published_dt.tzinfo is None:
                    published_dt = published_dt.replace(tzinfo=timezone.utc)
            except Exception:
                published_dt = None
            if published_dt is None or published_dt < min_date or published_dt > now + timedelta(days=1):
                continue
            news_item = {
                'title': entry.title,
                'summary': entry.summary if 'summary' in entry else '',
                'link': entry.link,
                'source': source,
                'published_dt': published_dt,
                'category': category
            }
            news_data.append(news_item)
    news_data.sort(key=lambda x: x['published_dt'], reverse=True)
    cache.set(cache_key, news_data, 60*10)  # 10 dakika cache
    return news_data

def home(request):
    # Ã–nemli haberleri Ã§ek
    important_news = get_important_news(days=2)
    
    # PopÃ¼ler hisseleri Ã§ek
    stocks = [
            {'symbol': 'THYAO.IS', 'company': 'TÃ¼rk Hava YollarÄ±'},
        {'symbol': 'GARAN.IS', 'company': 'Garanti BankasÄ±'},
        {'symbol': 'AKBNK.IS', 'company': 'Akbank'},
        {'symbol': 'SISE.IS', 'company': 'ÅiÅŸecam'},
        {'symbol': 'YKBNK.IS', 'company': 'YapÄ± Kredi'},
        {'symbol': 'KCHOL.IS', 'company': 'KoÃ§ Holding'},
        {'symbol': 'EREGL.IS', 'company': 'EreÄŸli Demir Ã‡elik'},
        {'symbol': 'SASA.IS', 'company': 'Sasa Polyester'},
        {'symbol': 'TUPRS.IS', 'company': 'TÃ¼praÅŸ'},
        {'symbol': 'ISCTR.IS', 'company': 'Ä°ÅŸ BankasÄ±'},
        {'symbol': 'MIATK.IS', 'company': 'Mia Teknoloji'},
        {'symbol': 'FROTO.IS', 'company': 'Ford Otosan'},
    ]
    
    return render(request, 'home.html', {
        'stocks': stocks,
        'important_news': important_news
    })

def tavsiye_hisse(request):
    recommended_stocks = RecommendedStock.objects.filter(is_active=True)
    return render(request, 'tavsiye_hisse.html', {'recommended_stocks': recommended_stocks})

@csrf_exempt
def chatbot(request):
    if request.method == 'POST':
        try:
            data = json.loads(request.body)
            user_message = data.get('message', '').strip()
            user_id = request.META.get('REMOTE_ADDR', 'unknown')

            # Cache check
            cache_key = f"chat_response_{user_message}_{user_id}"
            cached_response = cache.get(cache_key)
            if cached_response:
                return JsonResponse({'response': cached_response})

            # Process the message
            response = process_user_message(user_message, user_id)
            
            # Cache the response
            cache.set(cache_key, response, CACHE_TIMEOUTS['chat_history'])
            
            return JsonResponse({'response': response})

        except Exception as e:
            logger.error(f"Chatbot error: {str(e)}")
            return JsonResponse({
                'response': "ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu. LÃ¼tfen tekrar dener misiniz? ğŸ™"
            })

    return JsonResponse({'error': 'GeÃ§ersiz istek metodu'}, status=400)

def process_user_message(message, user_id=None):
    """Process user message and generate appropriate response"""
    try:
        # Otomatik BIST hisse kodu algÄ±lama (baÅŸÄ±nda $ olsa da)
        match = re.search(r'\b\$?([A-Z]{3,5}\.IS)\b', message.upper())
        symbol = match.group(1) if match else None
        if symbol:
            symbol = symbol.upper().strip().replace('$', '')  # Tamamen temizle
            stock_data = get_stock_info(symbol)
            if stock_data:
                return generate_stock_analysis(symbol, stock_data)
        # Only apply rate limit for Gemini API/general conversation
        if user_id and not rate_limiter.is_allowed(user_id):
            return "ÃœzgÃ¼nÃ¼m, Ã§ok fazla istek aldÄ±m. LÃ¼tfen birkaÃ§ dakika sonra tekrar deneyin! ğŸ˜…"
        return generate_conversation_response(message)
    except Exception as e:
        logger.error(f"Message processing error: {str(e)}")
        return random.choice(GREETING_MESSAGES)

def get_stock_info(symbol):
    symbol = symbol.upper().strip().replace('$', '')  # Tamamen temizle
    cache_key = f"stock_info_{symbol}"
    cached = cache.get(cache_key)
    if cached:
        return cached
    try:
        stock = yf.Ticker(symbol)
        info = {
            'history': stock.history(period='1mo'),
            'info': stock.info,
            'recommendations': stock.recommendations,
            'major_holders': stock.major_holders,
            'institutional_holders': stock.institutional_holders,
            'news': stock.news
        }
        if not info['history'].empty:
            cache.set(cache_key, info, 60*30)  # 30 dakika cache
            return info
        return None  # Veri yoksa None dÃ¶n
    except Exception as e:
        if 'rate limit' in str(e).lower() or 'too many requests' in str(e).lower():
            return {'error': 'Ã‡ok sÄ±k sorgu yapÄ±ldÄ±, lÃ¼tfen birkaÃ§ dakika sonra tekrar deneyin.'}
        logger.error(f"Stock info error: {str(e)}")
        return None  # Hata olursa da None dÃ¶n

def generate_stock_analysis(symbol, stock_data):
    """KÄ±sa ve sohbet iÃ§in uygun hisse Ã¶zeti dÃ¶ndÃ¼rÃ¼r."""
    try:
        history = stock_data['history']
        info = stock_data['info']
        current_price = history['Close'][-1]
        price_change = current_price - history['Close'][0]
        price_change_pct = (price_change / history['Close'][0]) * 100
        target_price = info.get('targetMeanPrice', 'N/A')
        market_cap = info.get('marketCap', 'N/A')
        pe_ratio = info.get('trailingPE', 'N/A')
        company = info.get('shortName', symbol)
        return (
            f"{company} ({symbol}) Hisse Ã–zeti:\n"
            f"- GÃ¼ncel Fiyat: {current_price:.2f} TL\n"
            f"- Hedef Fiyat: {target_price} TL\n"
            f"- Piyasa DeÄŸeri: {market_cap:,} TL\n"
            f"- F/K OranÄ±: {pe_ratio}\n"
            f"- Son 1 AylÄ±k DeÄŸiÅŸim: {price_change_pct:+.2f}%"
        )
    except Exception as e:
        logger.error(f"Analysis generation error: {str(e)}")
        return "ÃœzgÃ¼nÃ¼m, analiz oluÅŸtururken bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin! ğŸ”„"

def generate_ai_analysis(symbol, stock_data):
    """Generate AI-powered analysis using Gemini"""
    try:
        api_key = 'AIzaSyCpdN84xuqoi5wKKYBq9GRyhxIIq6RFtyc'
        url = f'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}'
        history = stock_data['history']
        info = stock_data['info']
        current_price = history['Close'][-1]
        price_change = current_price - history['Close'][0]
        price_change_pct = (price_change / history['Close'][0]) * 100
        avg_volume = history['Volume'].mean()
        high = history['High'].max()
        low = history['Low'].min()
        target_price = info.get('targetMeanPrice', 'N/A')
        market_cap = info.get('marketCap', 'N/A')
        pe_ratio = info.get('trailingPE', 'N/A')
        prompt = f"""
Sen TDX AI Bot'sun. {symbol} hissesi iÃ§in aÅŸaÄŸÄ±daki YFINANCE verilerine dayanarak gÃ¼ncel, kÄ±sa ve maddeler halinde bilgi ver:

- Son fiyat: {current_price:.2f} TL
- AylÄ±k deÄŸiÅŸim: {price_change_pct:.2f}%
- En yÃ¼ksek: {high:.2f} TL
- En dÃ¼ÅŸÃ¼k: {low:.2f} TL
- Ortalama hacim: {avg_volume:,.0f}
- Hedef fiyat: {target_price}
- Piyasa deÄŸeri: {market_cap}
- F/K oranÄ±: {pe_ratio}

KullanÄ±cÄ±ya kÄ±sa, samimi ve maddeler halinde bilgi ver. YatÄ±rÄ±m tavsiyesi verme, sadece veri ve Ã¶zet sun.
"""
        response = requests.post(
            url,
            headers={'Content-Type': 'application/json'},
            json={
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 1024
                }
            }
        )
        result = response.json()
        return result['candidates'][0]['content']['parts'][0]['text']
    except Exception as e:
        logger.error(f"AI analysis error: {str(e)}")
        return "Analiz oluÅŸturulurken bir hata oluÅŸtu, ama elimdeki verilere gÃ¶re dikkatli olmanÄ±zÄ± Ã¶neririm! ğŸ¤”"

def generate_performance_summary(history):
    """Generate performance summary"""
    try:
        monthly_return = ((history['Close'][-1] / history['Close'][0]) - 1) * 100
        avg_volume = history['Volume'].mean()
        
        return f"""
        ğŸ“Š AylÄ±k Getiri: {monthly_return:.2f}%
        ğŸ“ˆ Ortalama Ä°ÅŸlem Hacmi: {avg_volume:,.0f}
        """
    except Exception as e:
        logger.error(f"Performance summary error: {str(e)}")
        return "Performans Ã¶zeti hesaplanamadÄ±"

def generate_key_indicators(info):
    """Generate key financial indicators"""
    try:
        return f"""
        ğŸ¯ Hedef Fiyat: {info.get('targetMeanPrice', 'N/A')} TL
        ğŸ“Š Piyasa DeÄŸeri: {info.get('marketCap', 'N/A'):,} TL
        ğŸ“ˆ F/K OranÄ±: {info.get('trailingPE', 'N/A')}
        """
    except Exception as e:
        logger.error(f"Key indicators error: {str(e)}")
        return "GÃ¶stergeler hesaplanamadÄ±"

def generate_conversation_response(message):
    """Generate conversational response using Gemini"""
    try:
        api_key = 'AIzaSyBSJJob1ovfUYHgyV4pbKGF0uBuL5v7VxQ'
        url = f'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}'
        
        prompt = f"""
        Sen TDX AI Bot'sun. Borsa ve finans konularÄ±nda uzman, samimi ve yardÄ±msever bir asistansÄ±n.
        KullanÄ±cÄ± mesajÄ±: {message}
        
        LÃ¼tfen:
        1. Samimi ve arkadaÅŸÃ§a bir tonda yanÄ±t ver
        2. Emoji kullan
        3. Borsa ve finans konularÄ±nda yardÄ±mcÄ± ol
        4. soru sorma kÄ±sa ve Ã¶zlÃ¼ yanÄ±t ver.
        """
        
        response = requests.post(
            url,
            headers={'Content-Type': 'application/json'},
            json={
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 1024
                }
            }
        )
        
        result = response.json()
        return result['candidates'][0]['content']['parts'][0]['text']
    
    except Exception as e:
        logger.error(f"Conversation response error: {str(e)}")
        return random.choice(GREETING_MESSAGES)

@csrf_exempt
def get_stock_data_view(request):
    """Enhanced stock data endpoint"""
    if request.method == 'POST':
        try:
            data = json.loads(request.body)
            symbol = data.get('symbol', '')
            # Check cache
            cache_key = f"stock_data_{symbol}"
            cached_data = cache.get(cache_key)
            if cached_data:
                return JsonResponse(cached_data)
            # Get fresh data
            stock_info = get_stock_info(symbol)
            if not stock_info:
                return JsonResponse({
                    'error': 'ÃœzgÃ¼nÃ¼m, bu hisse iÃ§in veri bulamadÄ±m. DoÄŸru yazdÄ±ÄŸÄ±nÄ±zdan emin misiniz? ğŸ¤”'
                }, status=404)
            # Prepare response
            response_data = {
                'data': stock_info['history'].to_dict(orient='records'),
                'info': stock_info['info'],
                'analysis': generate_stock_analysis(symbol, stock_info),
                'recommendations': stock_info['recommendations'].to_dict(orient='records') if stock_info['recommendations'] is not None else [],
                'major_holders': stock_info['major_holders'].to_dict(orient='records') if stock_info['major_holders'] is not None else [],
                'news': stock_info['news']
            }
            # Cache the response
            cache.set(cache_key, response_data, CACHE_TIMEOUTS['stock_data'])
            return JsonResponse(response_data)
        except Exception as e:
            logger.error(f"Stock data error: {str(e)}")
            return JsonResponse({
                'error': 'Veri Ã§ekilirken bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin! ğŸ”„'
            }, status=500)
    return JsonResponse({'error': 'GeÃ§ersiz istek metodu'}, status=400)

def demo_view(request):
    return render(request, 'demo.html')

@csrf_protect
def kayit_view(request):
    if request.method == 'POST':
        if 'email_code' in request.POST:
            # Kod doÄŸrulama aÅŸamasÄ±
            input_code = request.POST.get('email_code')
            session_code = request.session.get('email_code')
            name = request.session.get('reg_name')
            email = request.session.get('reg_email')
            password = request.session.get('reg_password')
            if input_code == session_code:
                # KullanÄ±cÄ±yÄ± oluÅŸtur
                if ' ' in name:
                    first_name, last_name = name.split(' ', 1)
                else:
                    first_name, last_name = name, ''
                user = User.objects.create_user(username=email, email=email, password=password, first_name=first_name, last_name=last_name)
                user.save()
                login(request, user)
                # Temizle
                for key in ['email_code', 'reg_name', 'reg_email', 'reg_password']:
                    if key in request.session:
                        del request.session[key]
                return redirect('home')
            else:
                messages.error(request, 'Kod yanlÄ±ÅŸ!')
                return render(request, 'email_code.html')
        else:
            # Ä°lk kayÄ±t formu aÅŸamasÄ±
            name = request.POST.get('name', '').strip()
            email = request.POST.get('email')
            password = request.POST.get('password')
            password_confirm = request.POST.get('password_confirm')
            if password != password_confirm:
                messages.error(request, 'Åifreler eÅŸleÅŸmiyor.')
                return render(request, 'kayÄ±t.html')
            if User.objects.filter(username=email).exists():
                messages.error(request, 'Bu e-posta ile zaten bir hesap var.')
                return render(request, 'kayÄ±t.html')
            # Kod Ã¼ret ve gÃ¶nder
            code = str(random.randint(100000, 999999))
            request.session['email_code'] = code
            request.session['reg_name'] = name
            request.session['reg_email'] = email
            request.session['reg_password'] = password
            send_mail(
                'TDXBOT E-posta DoÄŸrulama Kodu',
                f'KayÄ±t iÅŸlemini tamamlamak iÃ§in doÄŸrulama kodunuz: {code}',
                None,
                [email],
                fail_silently=False,
            )
            return render(request, 'email_code.html')
    return render(request, 'kayÄ±t.html')

@csrf_protect
def giris_view(request):
    if request.method == 'POST':
        email = request.POST.get('email')
        password = request.POST.get('password')
        user = authenticate(request, username=email, password=password)
        if user is not None:
            login(request, user)
            return redirect('home')
        else:
            messages.error(request, 'E-posta veya ÅŸifre hatalÄ±.')
            return render(request, 'login.html')
    return render(request, 'login.html')

def cikis_view(request):
    logout(request)
    return redirect('home')

def stock_card(request):
    symbol = request.GET.get('symbol')
    user_ip = request.META.get('REMOTE_ADDR', 'unknown')
    stock = get_stock_data(symbol, user_ip=user_ip)
    return render(request, "partials/stock_card.html", {"stock": stock})

@csrf_exempt
def get_analysis(request):
    """Grafik verilerinden destek/direnÃ§ ve kapanÄ±ÅŸ fiyatlarÄ± ile Gemini API'den aÃ§Ä±klayÄ±cÄ±, senaryolu ve HTML formatÄ±nda analiz alÄ±r."""
    if request.method != 'POST':
        return JsonResponse({'status': 'error', 'error': 'GeÃ§ersiz istek.'}, status=400)
    try:
        data = json.loads(request.body)
        closes = data.get('closes', [])
        dates = data.get('dates', [])
        symbol = request.GET.get('symbol', '')
        if not closes or not dates or not symbol:
            return JsonResponse({'status': 'error', 'error': 'Veri eksik.'}, status=400)
        # Destek/direnÃ§ hesapla
        support_levels, resistance_levels = find_support_resistance(closes)
        # Daha aÃ§Ä±klayÄ±cÄ±, senaryolu ve HTML formatÄ±nda analiz iÃ§in prompt
        prompt = f"""
Sen bir borsa teknik analiz asistanÄ±sÄ±n. KullanÄ±cÄ± sana {symbol} hissesinin son 1 aylÄ±k kapanÄ±ÅŸ fiyatlarÄ±nÄ±, destek ve direnÃ§ seviyelerini verdi.
KapanÄ±ÅŸ fiyatlarÄ±: {closes}
Tarihler: {dates}
Destek seviyeleri: {support_levels}
DirenÃ§ seviyeleri: {resistance_levels}

LÃ¼tfen aÅŸaÄŸÄ±daki gibi detaylÄ± ve HTML formatÄ±nda teknik analiz hazÄ±rla:
- <h2>{symbol} Hisse Senedi Teknik Analizi (Son 1 Ay)</h2>
- <b>Fiyat Hareketi</b> baÅŸlÄ±ÄŸÄ± altÄ±nda kÄ±sa ve aÃ§Ä±klayÄ±cÄ± bir Ã¶zet ver.
- <b>Destek Seviyeleri</b> ve <b>DirenÃ§ Seviyeleri</b> baÅŸlÄ±klarÄ± ile seviyeleri <ul><li>maddeler halinde</li></ul> belirt.
- <b>OlasÄ± Senaryolar</b> baÅŸlÄ±ÄŸÄ± altÄ±nda en az 3 farklÄ± teknik senaryo Ã¼ret:
    <ul>
      <li><b>Destek KÄ±rÄ±lÄ±rsa:</b> ...</li>
      <li><b>DirenÃ§ AÅŸÄ±lÄ±rsa:</b> ...</li>
      <li><b>Yatayda KalÄ±rsa:</b> ...</li>
      <li><b>Ekstra Senaryo:</b> (hacim artÄ±ÅŸÄ±, haber etkisi, vb. gibi hisseye Ã¶zel bir durum)</li>
    </ul>
- Her senaryoda fiyatÄ±n hangi seviyelere gidebileceÄŸini, yatÄ±rÄ±mcÄ±larÄ±n nelere dikkat etmesi gerektiÄŸini ve teknik gÃ¶stergelerin ne anlama geldiÄŸini kÄ±sa kÄ±sa aÃ§Ä±kla.
- Sonucu <b>ÅŸÄ±k ve okunaklÄ± HTML</b> ile, baÅŸlÄ±klar, <ul> listeler, <span style='color:...'> gibi vurgularla sun.
- YatÄ±rÄ±m tavsiyesi verme, sadece teknik veriye dayalÄ± Ã¶zet sun.
"""
        api_key = 'AIzaSyCpdN84xuqoi5wKKYBq9GRyhxIIq6RFtyc'
        url = f'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}'
        response = requests.post(
            url,
            headers={'Content-Type': 'application/json'},
            json={
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 1024
                }
            }
        )
        result = response.json()
        analysis = result['candidates'][0]['content']['parts'][0]['text'] if 'candidates' in result else 'Analiz alÄ±namadÄ±.'
        cache_key_raw = f"analysis_{symbol}_{str(closes)}_{str(dates)}"
        cache_key = 'analysis_' + hashlib.sha256(cache_key_raw.encode('utf-8')).hexdigest()
        cache.set(cache_key, analysis, 60*60)  # 1 saat cache
        return JsonResponse({'status': 'success', 'data': {'analysis': analysis, 'cached': False}})
    except Exception as e:
        logger.error(f"get_analysis error: {str(e)}")
        return JsonResponse({'status': 'error', 'error': 'Analiz alÄ±nÄ±rken hata oluÅŸtu.'}, status=500) 

@require_GET
def important_news_api(request):
    days = int(request.GET.get('days', 2))
    news = get_important_news(days=days)
    # Sadece gerekli alanlarÄ± dÃ¶ndÃ¼r
    news_data = [
        {
            'title': n['title'],
            'summary': n['summary'],
            'link': n['link'],
            'source': n['source'],
            'published_dt': n['published_dt'].strftime('%d.%m.%Y %H:%M') if n['published_dt'] else '',
            'category': n['category']
        }
        for n in news
    ]
    return JsonResponse({'important_news': news_data}) 

def analyze_stock_image_with_gemini(image_path):
    if not PIL_AVAILABLE:
        return "PIL (Pillow) modÃ¼lÃ¼ bulunamadÄ±. GÃ¶rsel analizi Ã¶zelliÄŸi devre dÄ±ÅŸÄ±."
    
    try:
        GEMINI_API_KEY = 'AIzaSyBSJJob1ovfUYHgyV4pbKGF0uBuL5v7VxQ'
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')

        image = Image.open(image_path)
        image = image.convert('RGB')

        prompt = """
        AÅŸaÄŸÄ±daki gÃ¶rselde bir tablo var. LÃ¼tfen:
        - Tablodaki tÃ¼m baÅŸlÄ±klarÄ± ve satÄ±rlarÄ± eksiksiz olarak oku.
        - Tabloyu, baÅŸlÄ±klarÄ± ve satÄ±rlarÄ±yla birlikte, sadece HTML <table> etiketiyle dÃ¶ndÃ¼r.
        - Tabloyu profesyonel ve okunaklÄ± yap: <table> etiketine border, baÅŸlÄ±k satÄ±rÄ±na <thead>, zebra (alternatif satÄ±r rengi) ve okunabilirlik iÃ§in stil ekle.
        - Tablo baÅŸlÄ±ÄŸÄ±nÄ± <caption> etiketiyle ekle (varsa).
        - Sadece tabloyu dÃ¶ndÃ¼r, baÅŸka aÃ§Ä±klama veya yorum ekleme.
        """

        response = model.generate_content([prompt, image])
        return response.text

    except Exception as e:
        logging.error(f"Gemini API error: {str(e)}")
        return f"Analiz sÄ±rasÄ±nda hata oluÅŸtu: {str(e)}"

def stock_image_analysis_view(request):
    """Hisse gÃ¶rsel analizi sayfasÄ± (yetkili kullanÄ±cÄ± yÃ¼kleyebilir, diÄŸerleri sadece gÃ¶rebilir)"""
    can_upload = request.user.has_perm('stockdb.can_upload_stock_image')
    if can_upload and request.method == 'POST':
        if not PIL_AVAILABLE:
            messages.error(request, 'PIL (Pillow) modÃ¼lÃ¼ bulunamadÄ±. GÃ¶rsel analizi Ã¶zelliÄŸi devre dÄ±ÅŸÄ±.')
            return redirect('stock_image_analysis')
            
        title = request.POST.get('title')
        description = request.POST.get('description')
        image = request.FILES.get('image')
        if title and image:
            stock_image = StockImage.objects.create(
                title=title,
                description=description,
                image=image
            )
            image_path = stock_image.image.path
            analysis = analyze_stock_image_with_gemini(image_path)
            stock_image.gemini_analysis = analysis
            stock_image.is_analyzed = True
            stock_image.save()
            messages.success(request, 'GÃ¶rsel baÅŸarÄ±yla yÃ¼klendi ve analiz edildi!')
            return redirect('stock_image_analysis')
    stock_images = StockImage.objects.all().order_by('-created_at')
    return render(request, 'stock_image_analysis.html', {
        'stock_images': stock_images,
        'can_upload': can_upload,
        'pil_available': PIL_AVAILABLE
    })

@login_required
def delete_stock_image(request, image_id):
    if not request.user.has_perm('stockdb.can_upload_stock_image'):
        return HttpResponse('Yetkiniz yok.', status=403)
    stock_image = get_object_or_404(StockImage, id=image_id)
    stock_image.delete()
    messages.success(request, 'GÃ¶rsel baÅŸarÄ±yla silindi!')
    return redirect('stock_image_analysis') 